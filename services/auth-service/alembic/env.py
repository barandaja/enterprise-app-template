"""
Alembic environment configuration for the auth service.

This module configures Alembic to work with SQLAlchemy async models
and provides both offline and online migration capabilities.
"""
import asyncio
import os
from logging.config import fileConfig
from typing import Any, Dict

from alembic import context
from sqlalchemy import pool, engine_from_config
from sqlalchemy.ext.asyncio import create_async_engine

# Import all models to ensure they are registered with SQLAlchemy metadata
from src.models.base import Base
from src.models.user import User, Role, Permission, UserRole, RolePermission
from src.models.session import UserSession
from src.models.audit import AuditLog
from src.core.config import settings

# This is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Add your model's MetaData object here for 'autogenerate' support
target_metadata = Base.metadata

# Override database URL from environment if available
database_url = os.getenv("DATABASE_URL") or settings.DATABASE_URL
if database_url:
    config.set_main_option("sqlalchemy.url", database_url)


def get_url() -> str:
    """
    Get database URL for migrations.
    
    Returns:
        str: Database connection URL
        
    Note:
        Converts async URL to sync URL for standard Alembic operations
    """
    url = config.get_main_option("sqlalchemy.url")
    
    # Convert asyncpg URL to psycopg2 URL for sync operations
    if url and url.startswith("postgresql+asyncpg://"):
        url = url.replace("postgresql+asyncpg://", "postgresql+psycopg2://")
    elif url and url.startswith("postgresql://"):
        # Ensure we use psycopg2 explicitly for sync operations
        url = url.replace("postgresql://", "postgresql+psycopg2://")
    
    return url


def include_name(name: str, type_: str, parent_names: Dict[str, Any]) -> bool:
    """
    Determine whether to include a database object in migrations.
    
    Args:
        name: Name of the database object
        type_: Type of object (table, column, etc.)
        parent_names: Dictionary of parent object names
        
    Returns:
        bool: True if the object should be included
        
    Note:
        This function filters out objects that shouldn't be managed
        by Alembic (e.g., PostGIS extensions, system tables)
    """
    # Skip system tables and extensions
    if type_ == "table":
        # Skip PostGIS and other extension tables
        if name.startswith(("spatial_ref_sys", "geography_columns", "geometry_columns")):
            return False
        
        # Skip temporary tables
        if name.startswith("temp_"):
            return False
    
    return True


def include_object(object, name: str, type_: str, reflected: bool, compare_to: Any) -> bool:
    """
    Determine whether to include a reflected database object in migrations.
    
    Args:
        object: The database object
        name: Name of the object
        type_: Type of object
        reflected: Whether the object was reflected from the database
        compare_to: The object being compared to (if any)
        
    Returns:
        bool: True if the object should be included
        
    Note:
        This provides more fine-grained control over what gets included
        in autogenerated migrations
    """
    # Include all objects by default, but could add custom logic here
    return True


def run_migrations_offline() -> None:
    """
    Run migrations in 'offline' mode.

    This configures the context with just a URL and not an Engine,
    though an Engine is acceptable here as well. By skipping the Engine
    creation we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.
    """
    url = get_url()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        include_name=include_name,
        include_object=include_object,
        # Compare types to handle PostgreSQL-specific types properly
        compare_type=True,
        # Compare server defaults
        compare_server_default=True,
        # Render batch mode for better SQLite support (if needed)
        render_as_batch=False,
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection) -> None:
    """
    Execute migrations with the given database connection.
    
    Args:
        connection: Database connection object
        
    Note:
        This function is called by both sync and async migration runners
    """
    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        include_name=include_name,
        include_object=include_object,
        # Compare types to handle PostgreSQL-specific types properly
        compare_type=True,
        # Compare server defaults
        compare_server_default=True,
        # Transaction per migration for better error handling
        transaction_per_migration=True,
    )

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations() -> None:
    """
    Run migrations in async mode for use with asyncpg.
    
    This creates an async engine and runs migrations within
    an async context to support SQLAlchemy async operations.
    
    Note:
        This is the preferred method when using async SQLAlchemy
        with asyncpg driver
    """
    # Get the database URL and ensure it's async-compatible
    database_url = os.getenv("DATABASE_URL") or settings.DATABASE_URL
    
    # Ensure URL uses asyncpg driver
    if not database_url.startswith("postgresql+asyncpg://"):
        if database_url.startswith("postgresql://"):
            database_url = database_url.replace("postgresql://", "postgresql+asyncpg://")
        else:
            raise ValueError("Database URL must be a PostgreSQL URL")
    
    # Create async engine with connection pooling
    engine = create_async_engine(
        database_url,
        poolclass=pool.NullPool,  # Don't use connection pooling for migrations
        echo=False,  # Set to True for SQL debugging
        future=True,
    )

    # Run migrations within async context
    async with engine.connect() as connection:
        # Use run_sync to execute the synchronous migration context
        # within the async connection
        await connection.run_sync(do_run_migrations)

    # Dispose of the engine
    await engine.dispose()


def run_migrations_online() -> None:
    """
    Run migrations in 'online' mode.

    In this scenario we need to create an Engine and associate
    a connection with the context. This supports both sync and async modes.
    """
    # Check if we should use async mode
    database_url = os.getenv("DATABASE_URL") or settings.DATABASE_URL
    use_async = database_url and "asyncpg" in database_url
    
    if use_async:
        # Run async migrations
        asyncio.run(run_async_migrations())
    else:
        # Run sync migrations (fallback)
        # Ensure we use the correct URL with psycopg2 driver
        config_dict = config.get_section(config.config_ini_section, {})
        config_dict["sqlalchemy.url"] = get_url()
        
        connectable = engine_from_config(
            config_dict,
            prefix="sqlalchemy.",
            poolclass=pool.NullPool,
        )

        with connectable.connect() as connection:
            do_run_migrations(connection)


# Determine which migration mode to use
if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()